{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9b56c79-2fdc-4092-b3aa-4d54ced7cb61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Silver Notebook\n",
    "This notebook reads data from bronze tables, performs transformations and then stores them in silver tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c233eee0-0864-4c43-bc65-39af723b430f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Lets define the scehma for our json object in order for spark to process it from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2d1a7d7-252e-47a2-b0e6-edb5eb65fb13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr, from_json, explode, posexplode, cast, row_number\n",
    "from pyspark.sql.types import StructType, StructField, MapType, StringType, ArrayType, IntegerType\n",
    "from pyspark.sql import Window\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"dataset\", StructType([\n",
    "        StructField(\"dimension\", StructType([\n",
    "            StructField(\"id\", ArrayType(StringType()), True),\n",
    "            StructField(\"size\", ArrayType(IntegerType()), True),\n",
    "            StructField(\"measure\", StructType([\n",
    "                StructField(\"category\", StructType([\n",
    "                    StructField(\"index\", MapType(StringType(), StringType()), True),\n",
    "                    StructField(\"label\", MapType(StringType(), StringType()), True)\n",
    "                ]))\n",
    "            ])),\n",
    "\n",
    "            StructField(\"alue\", StructType([\n",
    "                StructField(\"category\", StructType([\n",
    "                    StructField(\"index\", MapType(StringType(), StringType()), True),\n",
    "                    StructField(\"label\", MapType(StringType(), StringType()), True)\n",
    "                ]))\n",
    "            ])),\n",
    "            StructField(\"ammatti\", StructType([\n",
    "                StructField(\"category\", StructType([\n",
    "                    StructField(\"index\", MapType(StringType(), StringType()), True),\n",
    "                    StructField(\"label\", MapType(StringType(), StringType()), True)\n",
    "                ]))\n",
    "            ])),\n",
    "            StructField(\"palvelumuoto\", StructType([\n",
    "                StructField(\"category\", StructType([\n",
    "                    StructField(\"index\", MapType(StringType(), StringType()), True),\n",
    "                    StructField(\"label\", MapType(StringType(), StringType()), True)\n",
    "                ]))\n",
    "            ])),\n",
    "            StructField(\"aika\", StructType([\n",
    "                StructField(\"category\", StructType([\n",
    "                    StructField(\"index\", MapType(StringType(), StringType()), True),\n",
    "                    StructField(\"label\", MapType(StringType(), StringType()), True)\n",
    "                ]))\n",
    "            ])),\n",
    "        ])),\n",
    "        StructField(\"value\", MapType(StringType(), StringType()))\n",
    "    ]))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "953cd588-778c-4640-85c0-94fa615021c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Defining the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "539b9cc6-a96b-4d7f-b63b-f91df326e08c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform (table_df):\n",
    "  # Step 2: Parse JSON\n",
    "  parsed = table_df.withColumn(\"data\", from_json(col(\"json_response\"), schema)).drop(\"json_response\")\n",
    "\n",
    "  # Step 3: Extract dimensions and values as key-value pairs and then sort them with respect to the sort index\n",
    "  values_df = parsed.selectExpr(\"explode(data.dataset.value) as (key, value)\")\n",
    "\n",
    "  regions = parsed.selectExpr(\"\"\"\n",
    "      explode(data.dataset.dimension.alue.category.label) as (region_id, region_name)\n",
    "  \"\"\").join(\n",
    "      parsed.selectExpr(\"explode(data.dataset.dimension.alue.category.index) as (region_id, sort_index_range)\"),\n",
    "      on=\"region_id\",\n",
    "      how=\"left\"\n",
    "  ).withColumn(\n",
    "      \"sort_index_range\", col(\"sort_index_range\").cast(\"int\")\n",
    "  ).orderBy(\"sort_index_range\").drop(col(\"region_id\"))\n",
    "\n",
    "  professions = parsed.selectExpr(\"\"\"\n",
    "      explode(data.dataset.dimension.ammatti.category.label) as (profession_id, profession_name)\n",
    "  \"\"\").join(\n",
    "      parsed.selectExpr(\"explode(data.dataset.dimension.ammatti.category.index) as (profession_id, sort_index_profession)\"),\n",
    "      on=\"profession_id\",\n",
    "      how=\"left\"\n",
    "  ).withColumn(\n",
    "      \"sort_index_profession\", col(\"sort_index_profession\").cast(\"int\")\n",
    "  ).orderBy(\"sort_index_profession\").drop(col(\"profession_id\"))\n",
    "\n",
    "  service_types = parsed.selectExpr(\"\"\"\n",
    "      explode(data.dataset.dimension.palvelumuoto.category.label) as (service_type_id, service_type_name)\n",
    "  \"\"\").join(\n",
    "      parsed.selectExpr(\"explode(data.dataset.dimension.palvelumuoto.category.index) as (service_type_id, sort_index_service_type)\"),\n",
    "      on=\"service_type_id\",\n",
    "      how=\"left\"\n",
    "  ).withColumn(\n",
    "      \"sort_index_service_type\", col(\"sort_index_service_type\").cast(\"int\")\n",
    "  ).orderBy(\"sort_index_service_type\").drop(col(\"service_type_id\"))\n",
    "\n",
    "  years = parsed.selectExpr(\"\"\"\n",
    "      explode(data.dataset.dimension.aika.category.label) as (year_id, year)\n",
    "  \"\"\").join(\n",
    "      parsed.selectExpr(\"explode(data.dataset.dimension.aika.category.index) as (year_id, sort_index_year)\"),\n",
    "      on=\"year_id\",\n",
    "      how=\"left\"\n",
    "  ).withColumn(\n",
    "      \"sort_index_year\", col(\"sort_index_year\").cast(\"int\")\n",
    "  ).orderBy(\"sort_index_year\").drop(col(\"year_id\"))\n",
    "\n",
    "  # Step 4: Cross join with your original data to get dimensions\n",
    "  base_df = regions.crossJoin(professions).crossJoin(service_types).crossJoin(years)\n",
    "  w = Window.orderBy(\"sort_index_range\", \"sort_index_profession\", \"sort_index_service_type\", \"sort_index_year\")\n",
    "  base_df = base_df.withColumn(\"row_number\", row_number().over(w)-1).drop(\"sort_index_range\", \"sort_index_profession\", \"sort_index_service_type\", \"sort_index_year\")\n",
    "\n",
    "  # Step 5: Join with values df to get one final\n",
    "  result_df = base_df.join(\n",
    "      values_df.select(\n",
    "          col(\"key\").alias(\"row_number\"),\n",
    "          col(\"value\")\n",
    "      ), \n",
    "      \"row_number\", \n",
    "      \"left\"  # Use left join to keep all combinations, null for missing values\n",
    "  ).select(\n",
    "      \"region_name\",\n",
    "      \"profession_name\", \n",
    "      \"service_type_name\", \n",
    "      \"year\", \n",
    "      \"value\"\n",
    "  )\n",
    "\n",
    "  # Step 6: Removing the total aggregate data\n",
    "  result_df = result_df.filter(col('region_name')!='Kaikki kunnat')\n",
    "  result_df = result_df.filter(col('profession_name')!='Kaikki ammatit')\n",
    "  result_df = result_df.filter(col('service_type_name')!='Kaikki palvelumuodot')\n",
    "  result_df = result_df.filter(\n",
    "      (col('year') != 'Kaikki vuodet')\n",
    "  )\n",
    "\n",
    "  # Step 7: Changing the data type of certain columns\n",
    "  result_df = result_df.withColumn(\"value\", expr(\"try_cast(value as double)\")).withColumn(\"year\", expr(\"try_cast(year as int)\"))\n",
    "\n",
    "  return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7331243-5aa8-4075-9c34-82d1e4f992f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Setting up the catalog and database\n",
    "spark.catalog.setCurrentCatalog(\"silver\")\n",
    "spark.catalog.setCurrentDatabase(\"avohilmo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "738c09f8-4238-4271-a461-e72a599dd2b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create an empty table with data types\n",
    "CREATE TABLE IF NOT EXISTS visits_processed (\n",
    "  region_name STRING,\n",
    "  profession_name STRING,\n",
    "  service_type_name STRING,\n",
    "  year INT,\n",
    "  value INT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS customers_processed (\n",
    "  region_name STRING,\n",
    "  profession_name STRING,\n",
    "  service_type_name STRING,\n",
    "  year INT,\n",
    "  value INT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS visits_customers_processed (\n",
    "  region_name STRING,\n",
    "  profession_name STRING,\n",
    "  service_type_name STRING,\n",
    "  year INT,\n",
    "  value DOUBLE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a227895-146b-42ac-9c91-c89d7f3ffe14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Main runner code\n",
    "visits_raw_df = spark.table(\"bronze.avohilmo.visits_raw\")\n",
    "visits_raw_df = visits_raw_df.orderBy(col(\"created_at\").desc()).limit(1)\n",
    "visits_raw_df = transform(visits_raw_df)\n",
    "\n",
    "# Cast value to int\n",
    "visits_raw_df = visits_raw_df.withColumn(\n",
    "    \"value\", col(\"value\").cast(\"int\")\n",
    ")\n",
    "visits_raw_df.write.mode(\"overwrite\").saveAsTable(\"silver.avohilmo.visits_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5c6b7d0-4a3d-4dd0-8f56-2ee0e088a97f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers_raw_df = spark.table(\"bronze.avohilmo.customers_raw\")\n",
    "customers_raw_df = customers_raw_df.orderBy(col(\"created_at\").desc()).limit(1)\n",
    "customers_raw_df = transform(customers_raw_df)\n",
    "\n",
    "# Cast value to int\n",
    "customers_raw_df = customers_raw_df.withColumn(\n",
    "    \"value\", col(\"value\").cast(\"int\")\n",
    ")\n",
    "customers_raw_df.write.mode(\"overwrite\").saveAsTable(\"silver.avohilmo.customers_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e136e09e-82ab-4392-a584-8dd7f6dad88d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "visits_customers_raw_df = spark.table(\"bronze.avohilmo.visits_customers_raw\")\n",
    "visits_customers_raw_df = visits_customers_raw_df.orderBy(col(\"created_at\").desc()).limit(1)\n",
    "visits_customers_raw_df = transform(visits_customers_raw_df)\n",
    "visits_customers_raw_df.write.mode(\"overwrite\").saveAsTable(\"silver.avohilmo.visits_customers_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from silver.avohilmo.visits_processed;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from silver.avohilmo.customers_processed;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from silver.avohilmo.visits_customers_processed;   "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8893800372763848,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver-notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
